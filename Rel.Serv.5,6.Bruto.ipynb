{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede97bb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike, integer or None, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m size\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbancos_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;66;03m# Extrai data e servidor do nome do arquivo\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbancos_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{8}\u001b[39;00m\u001b[38;5;124m)_s(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, filename)\n",
      "\u001b[0;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike, integer or None, not dict"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho dos arquivos\n",
    "base_path = {'s5': '../data_raw/s5Bruto','s6': '../data_raw/s6Bruto'}\n",
    "saida_excel = \"../data_raw/saida_bancos.xlsx\"\n",
    "log_path = \"../data_raw/log_bancos.txt\"\n",
    "\n",
    "# Regex para capturar linhas válidas da tabela\n",
    "line_regex = re.compile(\n",
    "    r'^\\s*([\\w_]+)\\s+\\|\\s+\\w+\\s+\\|\\s+\\w+\\s+\\|\\s+\\S+\\s+\\|\\s+\\S+\\s+\\|\\s+\\S*\\s+\\|\\s+([\\d\\.]+)\\s*(MB|GB|kB)\\s+\\|\\s+\\w+\\s+\\|',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "dados = []\n",
    "arquivos_processados = []\n",
    "\n",
    "def size_to_mb(size, unit):\n",
    "    size = float(size.replace(',', ''))\n",
    "    if unit.upper() == 'GB':\n",
    "        return size * 1024\n",
    "    elif unit.upper() == 'MB':\n",
    "        return size\n",
    "    elif unit.upper() == 'KB':\n",
    "        return size / 1024\n",
    "    return size\n",
    "\n",
    "for filename in os.listdir(base_path):\n",
    "    if filename.startswith(\"bancos_\") and filename.endswith(\".txt\"):\n",
    "        # Extrai data e servidor do nome do arquivo\n",
    "        match = re.match(r'bancos_(\\d{8})_s(\\d)\\.txt', filename)\n",
    "        if not match:\n",
    "            arquivos_processados.append(f'❌ {filename} - Nome fora do padrão')\n",
    "            continue\n",
    "        data_raw, servidor = match.groups()\n",
    "        data_formatada = f\"{data_raw[6:8]}/{data_raw[4:6]}/{data_raw[:4]}\"\n",
    "        try:\n",
    "            with open(os.path.join(base_path, filename), 'r') as file:\n",
    "                for line in file:\n",
    "                    m = line_regex.match(line)\n",
    "                    if m:\n",
    "                        base, size, unit = m.groups()\n",
    "                        tamanho_mb = size_to_mb(size, unit)\n",
    "                        tipo = \"arq\" if base.startswith(\"arq_\") else \"normal\"\n",
    "                        dados.append({\n",
    "                            \"Data\": data_formatada,\n",
    "                            \"Servidor\": f\"s{servidor}\",\n",
    "                            \"Base\": base,\n",
    "                            \"Tamanho (MB)\": round(tamanho_mb, 2),\n",
    "                            \"Tipo\": tipo\n",
    "                        })\n",
    "            arquivos_processados.append(f'✅ {filename}')\n",
    "        except Exception as e:\n",
    "            arquivos_processados.append(f'❌ {filename} - Erro: {e}')\n",
    "\n",
    "# Salvar log de arquivos\n",
    "with open(log_path, 'w') as log_file:\n",
    "    log_file.write('\\n'.join(arquivos_processados))\n",
    "\n",
    "# Criar DataFrame e processar os dados\n",
    "df = pd.DataFrame(dados)\n",
    "\n",
    "# Agrupamento geral\n",
    "df_agrupado = df.groupby(['Data', 'Servidor', 'Base', 'Tipo'], as_index=False)['Tamanho (MB)'].sum()\n",
    "df_ordenado = df_agrupado.sort_values(by=['Base', 'Data'])\n",
    "\n",
    "# Totais por Base e Servidor\n",
    "df_totais = df_ordenado.groupby(['Servidor', 'Base', 'Tipo'], as_index=False)['Tamanho (MB)'].sum()\n",
    "\n",
    "# Tamanhos separados por tipo\n",
    "df_arq = df[df['Tipo'] == 'arq'].groupby(['Servidor', 'Base', 'Data'], as_index=False)['Tamanho (MB)'].sum()\n",
    "df_normal = df[df['Tipo'] == 'normal'].groupby(['Servidor', 'Base', 'Data'], as_index=False)['Tamanho (MB)'].sum()\n",
    "\n",
    "# Crescimento por Base e Data (apenas arquivos normais)\n",
    "df_crescimento = df_normal.copy()\n",
    "df_crescimento = df_crescimento.sort_values(['Servidor', 'Base', 'Data'])\n",
    "df_crescimento['Crescimento (%)'] = df_crescimento.groupby(['Servidor', 'Base'])['Tamanho (MB)'].pct_change() * 100\n",
    "df_crescimento['Diferença (MB)'] = df_crescimento.groupby(['Servidor', 'Base'])['Tamanho (MB)'].diff()\n",
    "\n",
    "# Exportar tudo em um único Excel com múltiplas abas\n",
    "with pd.ExcelWriter(saida_excel, engine='openpyxl') as writer:\n",
    "    df_ordenado.to_excel(writer, sheet_name='Resumo por Base', index=False)\n",
    "    df_totais.to_excel(writer, sheet_name='Totais por Base', index=False)\n",
    "    df_crescimento.to_excel(writer, sheet_name='Crescimento (%)', index=False)\n",
    "    df_arq.to_excel(writer, sheet_name='Apenas arq', index=False)\n",
    "    df_normal.to_excel(writer, sheet_name='Apenas normal', index=False)\n",
    "\n",
    "print(f'✅ Relatório completo exportado para: {saida_excel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a2a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
